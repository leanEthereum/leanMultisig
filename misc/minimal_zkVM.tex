\documentclass{article}

\usepackage[english]{babel}

\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{framed}
\usepackage{tikz}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{tcolorbox}
\usepackage{amsthm}
\usetikzlibrary{positioning, arrows.meta}

\theoremstyle{definition}
\newtheorem{exmp}{Example}[section]

\definecolor{sigblue}{RGB}{214,228,247}
\definecolor{siggreen}{RGB}{208,235,203}
\definecolor{sigyellow}{RGB}{255,245,200}

\newcommand{\Fp}{\mathbb F_p}
\newcommand{\Fq}{\mathbb F_q}
\newcommand{\offdest}{\text{off}_{\text{dest}}}
\newcommand{\offopzero}{\text{off}_{\text{op0}}}
\newcommand{\offopone}{\text{off}_{\text{op1}}}
\newcommand*{\logeq}{\ratio\Leftrightarrow}

\newtheorem{lemma}{Lemma}

\title{Minimal zkVM for Lean Ethereum (draft 0.6.0)}
\date{}
\begin{document}

\maketitle

\tableofcontents
\newpage

\section{What is the goal of this zkVM?}
Post-quantum signatures are at least an order of magnitude larger than their pre-quantum counterparts, but the migration is necessary to ensure Ethereum's security. Hash-based signatures offer strong security guarantees and conceptual simplicity, making them a promising candidate: leanXMSS at the consensus layer (where statefulness is not an issue, see \cite{ethereum_signatures}, \cite{top_hypercube}, and \cite{LeanSig}), and leanSPHINCS at the execution layer. A promising choice of hash function is Poseidon2 \cite{poseidon2}, for its snark-friendliness.

Since post-quantum signatures are much larger, we need to aggregate them. However, they lack the algebraic structure that makes aggregation easy for elliptic-curve schemes like BLS. Instead, we can aggregate them using a snark---itself hash-based, keeping everything post-quantum.

Concretely, we need to:
\begin{itemize}
     \item \textbf{Aggregate} hash-based signatures (leanXMSS / leanSPHINCS)
    \item \textbf{Merge} those aggregate signatures $\rightarrow$ recursive proof
\end{itemize}

Both tasks mainly require proving a lot of hashes. A minimal zkVM (inspired by Cairo \cite{cairo}) is useful as glue to handle all the logic: leanVM.

Aggregation and merging are unified in a single program, that attests that a given set of signers have valid signatures for a given message. 

\begin{figure}[ht]
\centering
\begin{tikzpicture}[
    proof/.style={draw, rounded corners=4pt, minimum width=2.6cm, minimum height=1cm, align=center, font=\small},
    leaf/.style={proof},
    merge/.style={proof, line width=0.8pt},
    root/.style={proof, minimum width=3cm, line width=1.2pt},
    xmss/.style={draw, dashed, rounded corners=2pt, minimum width=1.6cm, minimum height=0.7cm, align=center, font=\scriptsize},
    attests/.style={font=\footnotesize, text=black!50},
    arr/.style={-{Stealth[length=5pt]}, thick},
    sigarr/.style={-{Stealth[length=4pt]}, densely dashed, thin},
]

% --- XMSS signature blocks (inputs) ---
\node[xmss] (S1) at (0, -1.8) {signers $1$--$2500$};
\node[xmss] (S2) at (3.5, -1.8) {signers $2501$--$5000$};
\node[xmss] (S3) at (7, -1.8) {signers $5001$--$7500$};
\node[xmss] (S4) at (10.5, -1.8) {signers $7501$--$10000$};

% --- Leaf proofs ---
\node[leaf] (L1) at (0, 0) {Proof $A$};
\node[leaf] (L2) at (3.5, 0) {Proof $B$};
\node[leaf] (L3) at (7, 0) {Proof $C$};

% XMSS -> leaf arrows
\draw[sigarr] (S1) -- (L1);
\draw[sigarr] (S2) -- (L2);
\draw[sigarr] (S3) -- (L3);

% --- Middle level ---
\node[merge] (M1) at (1.75, 2.5) {Proof $D$};
\node[merge] (M2) at (8.75, 2.5) {Proof $E$};

% XMSS -> E (direct group)
\draw[sigarr] (S4) -- (M2);

% Recursive arrows: leaves -> middle
\draw[arr] (L1) -- (M1);
\draw[arr] (L2) -- (M1);
\draw[arr] (L3) -- (M2);

% --- Root ---
\node[root] (R) at (5.25, 5) {Final proof};

% Recursive arrows: middle -> root
\draw[arr] (M1) -- (R);
\draw[arr] (M2) -- (R);

% --- Coverage annotations (above each proof) ---
\node[attests, above=8pt of L1] {$1\text{--}2500$};
\node[attests, above=8pt of L2] {$2501\text{--}5000$};
\node[attests, above=8pt of L3] {$5001\text{--}7500$};
\node[attests, above=8pt of M1] {$1\text{--}5000$};
\node[attests, above=8pt of M2] {$5001\text{--}10000$};
\node[attests, above=8pt of R] {$1\text{--}10000$};

\end{tikzpicture}
\caption{Example of recursive aggregation of 10000 signatures. (Note: overlapping sets of signers are possible.) }
\label{fig:recursive-aggregation}
\end{figure}


\section{VM specification}
\subsection{Field}

\fbox{KoalaBear prime: $p = 2^{31} - 2^{24} + 1$}

\vspace{3mm}

Advantages:
\begin{itemize}
    \item small field $\xrightarrow{}$ less Poseidon rounds
    \item $x \xrightarrow{} x^3$ is an automorphism of $\Fp^*$, meaning efficient S-box for Poseidon2 (in BabyBear, it's degree $7$)
    \item $< 2^{31}$ $\xrightarrow{}$ the sum of 2 field elements can be stored in an u32
\end{itemize}

The small 2-addicity (24) is not a limiting factor in WHIR, thanks to the use of an interleaved Reed Solomon code (example: with an initial folding of 7, and rate $1/2$, we can commit up to $2^{30}$ field elements).

\vspace{3mm}

\fbox{Extension field: $\Fq$, with $q = p^5$} : the degree-5 extension enables 128 bits of security in WHIR, with the Johnson bound, thanks to the latest result of \cite{proximity_gaps_rs_codes_2}.

\subsection{Memory}

\begin{itemize}
    \item Read-Only Memory
    \item Word = KoalaBear field element
    \item Memory size: $M = 2^m$ with $16 \leq m \leq 29$ ($m$ depends on the execution and is communicated at the beginning of the proof).
    \item The first $M' = 2^{m'}$ memory cells hold the "public input", on which both prover and verifier must agree.
    This enables to pass the arguments that the leanISA program receives as input (in our case: message to sign and XMSS public keys).
\end{itemize}

% \begin{figure}[h]
% \caption{Memory structure}
% \centering
% \label{memory}
% \includegraphics[scale=0.7]{images/memory.png}
% \end{figure}

\subsection{Registers}

% As in Cairo:
\begin{itemize}
    \item \fbox{pc: program counter}
    % \item \textbf{ap}: allocation pointer = Points to the first untouched memory cell
    \item \fbox{fp: frame pointer} : points to the start of the current stack
\end{itemize}


\textbf{Difference with Cairo: no "ap" register} (allocation pointer).


\subsection{Instruction Set Architecture}

Notations:
\begin{itemize}
    \item $\alpha$, $\beta$ and $\gamma$ represent parameters of the instructions (immediate value operands)
    \item $\textbf{m}[i]$ represents the value of the memory at index $i \in \Fp$, with $i < M$ ($M$: memory size). Any out-of-bound memory access ($i \geq M$) is invalid.
    \item $\begin{cases} A \\ B \end{cases}$ When using the instruction, either $A$ or $B$ can be used, but not both simultaneously.
\end{itemize}


\subsubsection{ADD / MUL}

ADD: $\nu_a + \nu_c = \nu_b$ \hspace{3mm} and \hspace{3mm} MUL: $\nu_a \cdot \nu_c = \nu_b$ with: 

\begin{align*}
\nu_a &= 
\begin{cases}
\alpha \\
\textbf{m}[\text{fp} + \alpha]
\end{cases}
&
\nu_b &= 
\begin{cases}
\beta \\
\textbf{m}[\text{fp} + \beta]
\end{cases}
&
\nu_c &= 
\begin{cases}
\gamma \\
\textbf{m}[\text{fp} + \gamma]  \\
\text{fp} + \gamma
\end{cases}
\end{align*}


\subsubsection{DEREF}

$$
\textbf{m}[\textbf{m}[\text{fp} + \alpha] + \beta] = 
\begin{cases}
& \gamma \\
& \textbf{m}[\text{fp} + \gamma]   \\
& \text{fp} + \gamma

\end{cases}
$$

\subsubsection{JUMP (Conditional)}

\begin{align*}
\text{condition} &= 
\begin{cases}
\alpha \\
\textbf{m}[\text{fp} + \alpha]
\end{cases} \in \{0, 1\}
&
\text{dest} &= 
\begin{cases}
\beta \\
\textbf{m}[\text{fp} + \beta]
\end{cases}
&
\text{updated\_fp} &=
\begin{cases}
\text{fp} + \gamma \\
\textbf{m}[\text{fp} + \gamma]
\end{cases}
\end{align*}

$$
\text{next(pc)} =
\begin{cases}
\text{dest} & \text{if condition} = 1 \\
\text{pc} + 1 & \text{if condition} = 0
\end{cases}
\qquad
\text{next(fp)} =
\begin{cases}
\text{updated\_fp} & \text{if condition} = 1 \\
\text{fp} & \text{if condition} = 0
\end{cases}
$$

\subsection{Precompiles}

There are two "precompile" instructions: DOT\_PRODUCT and POSEIDON2. Each precompile instruction has three (potentially runtime) parameters $\nu_A$, $\nu_B$, $\nu_C$, and a compile-time value \texttt{PRECOMPILE\_DATA}.

$\nu_A$, $\nu_B$, $\nu_C$ are defined similarly to the ADD/MUL instructions, with the additional possibility of $\nu_A = \text{fp} + \alpha$ and $\nu_B = \text{fp} + \beta$, but these two must be used simultaneously (if $\nu_A$ is fp-relative, then $\nu_B$ must be fp-relative too, and vice versa).

\subsubsection{POSEIDON2}

Compression of 16 field elements (two blocks of 8) into 8 field elements.

$$
\textbf{m}[\nu_C..\nu_C + 8] = \text{Poseidon2}(\textbf{m}[\nu_A..\nu_A + 8] | \textbf{m}[\nu_B..\nu_B + 8]) + \textbf{m}[\nu_A..\nu_A + 8]
$$

\vspace{2mm}

\texttt{PRECOMPILE\_DATA} $= 1$

\subsubsection{DOT\_PRODUCT}\label{dot_product_instruction}

Computes $\text{res} = \sum_{i=0}^{n-1} a_i \cdot b_i \in \Fq$, where:
\begin{itemize}
    \item \textbf{BE mode} (\texttt{is\_be} $= 1$): $a_i \in \Fp$, $b_i \in \Fq$ (base $\times$ extension), $a_i = \textbf{m}[\nu_A + i]$, $b_i = \textbf{m}[\nu_B + 5.i.. \nu_B + 5.(i+1)]$, res = $\textbf{m}[\nu_C.. \nu_C + 5]$
    \item \textbf{EE mode} (\texttt{is\_be} $= 0$): $a_i \in \Fq$, $b_i \in \Fq$ (extension $\times$ extension), $a_i = \textbf{m}[\nu_A + 5.i.. \nu_A + 5.(i+1)]$, $b_i = \textbf{m}[\nu_B + 5.i.. \nu_B + 5.(i+1)]$, res = $\textbf{m}[\nu_C.. \nu_C + 5]$
\end{itemize}

(Chunks of 5 field elements $\textbf{m}[x..x+5]$ are interpreted as an extension field element ($\Fq = {\mathbb F_{p^5}}$)).

\vspace{2mm}

\texttt{PRECOMPILE\_DATA} $= 2 \cdot (\texttt{is\_be} + 2 \cdot n)$, encoding both the mode and the length $n > 0$.

\subsection{ISA programming}

\subsubsection{Functions}

\begin{enumerate}
    \item Each function has a deterministic memory footprint: the length of the continuous frame in memory that is allocated for each of the its calls.
    \item At runtime, each time we call our function, we receive via a memory cell a hint pointing to a free range of memory. We then store the current values of pc / fp at the start of this newly allocated frame, alongside the function's arguments, we can then jump, to enter the function bytecode, and modify fp with the hinted value. The intuition here is that the verifier does not care where the new memory frame will be placed (we use a read-only memory, so we cannot overwrite previous frames). In practice, the prover that runs the program would need to keep the value of the allocation pointer "ap", in order to adequately allocate new memory frames, but there is no need to keep track of it from the versifier's perspective.
\end{enumerate}


\begin{figure}[h]
\caption{Memory layout of a function call}
\centering
\includegraphics[scale=0.4]{images/memory_layout.png}
\end{figure}

\subsubsection{Loops}\label{loops}

We suggest to unroll loops when the number of iterations is low, and known at compile time.
The remaining loops are transformed into recursive functions (by the leanISA compiler).

\subsubsection{Range checks}

\fbox{It's possible to check that a given memory cell is smaller than some value $t$ (for $t \leq 2^{16})$ in 3 cycles.}

We denote by \textbf{m}[fp + $x$] the memory cell for which we want to ensure \textbf{m}[fp + $x$] $< t$.
We also denote by \textbf{m}[fp + $i$], \textbf{m}[fp + $j$] and \textbf{m}[fp + $k$] 3 auxiliary memory cells (that have not been used yet).
\begin{enumerate}
    \item \textbf{m}[\textbf{m}[fp + $x$]] = \textbf{m}[fp + $i$] (using DEREF, this ensures \textbf{m}[fp + $x$] $ < M$, the memory size)
    \item \textbf{m}[\textbf{m}[fp + $x$]] + \textbf{m}[fp + $j$] = (t-1) (using ADD)
        \item \textbf{m}[\textbf{m}[fp + $j$]] = \textbf{m}[fp + $k$] (using DEREF, this ensures $t - 1 - $ \textbf{m}[fp + $x$] $ < M$)
\end{enumerate}

Given $t \leq 2^{16} \leq M$, \textbf{m}[fp + $x$] $ < M$, $t - 1 - $ \textbf{m}[fp + $x$] $< M$, and $M \leq 2^{29} < p / 2$, we have: \textbf{m}[fp + $x$] $ < t$.

Note: From the point of view of the prover running the program, some hints are necessary (filling the values of \textbf{m}[fp + $i$] and \textbf{m}[fp + $k$] must be done at end of execution).

This idea was pointed out by D. Khovratovich, and is an unplanned use of the DEREF instruction.

\begin{exmp}
	Let's say we want to write a function with 2 arguments $x = \textbf{m}$[fp + 2] and $y = \textbf{m}$[fp + 3] ($\textbf{m}$[fp + 0] and $\textbf{m}$[fp + 1] are used, by convention, to store the caller's pc and fp, to return to the previous context at the end of the function), which perform the following:
	
	\begin{enumerate}
		\item assert(x $<$ 10)
		\item z := x*y + 100
		\item assert(z $<$ 1000)
	\end{enumerate}
	
	Which can be compiled to:
	
	\begin{enumerate}
		\item \textbf{m}[fp + 4] = \textbf{m}[$\big[$fp + 2$\big]$] // check that $x$ is "small"
		\item \textbf{m}[fp + 2] + \textbf{m}[fp + 5] = 9 // compute $9 - x$
		\item \textbf{m}[fp + 6] = \textbf{m}[$\big[$fp + 5$\big]$] // check that $9 - x$ is "small"
		\item \textbf{m}[fp + 7] = \textbf{m}[fp + 2] * \textbf{m}[fp + 3] // compute $x.y$
		\item \textbf{m}[fp + 8] = \textbf{m}[fp + 7] + 100 // compute $z = x.y + 100$
		\item \textbf{m}[fp + 9] = \textbf{m}[$\big[$fp + 8$\big]$] // check that $z$ is "small"
		\item \textbf{m}[fp + 8] + \textbf{m}[fp + 10] = 999 // compute $999 - z$
		\item \textbf{m}[fp + 11] = \textbf{m}[$\big[$fp + 10$\big]$] // check that $999 - z$ is "small"
		\item JUMP with next(pc) = \textbf{m}[fp + 0], next(fp) = \textbf{m}[fp + 1], condition = 1 // return
	\end{enumerate}
	
	 
\end{exmp}


\subsubsection{Switch statements}

Suppose we want a different logic depending on the value $x$ of a given memory cell, where $x$ is known to be $< k$ (if the value $x$ comes from a "hint", don't forget to range-check it).

Each of the $k$ different value leads to a different branch at runtime, represented by a block of code. We want to jump to the correct block of code depending on $x$.
One efficient implementation consists in placing our blocks of code at regular intervals, and to jump to a $a+ b.x$, where $a$ is the offset of the first block of code (in case $x = 0$), and $b$ is the distance between two consecutive blocks.
\newline
\newline
Example: During XMSS verification, for each of the $v$ chains, we need to hash a pre-image, a number of times depending on the encoding, but known to be $< w$. Here $k = w$, and the $i-th$ block of code we could jump to will execute $i$ times the hash function (unrolled loop).

\section{Proving system}\label{sec:proving}

\subsection{Table sizes}\label{sec:table-sizes}

Each table has a maximum number of rows (as a power of two):

\begin{center}
\begin{tabular}{lc}
\toprule
Table & Max rows \\
\midrule
Execution & $2^{25}$ \\
Dot product & $2^{21}$ \\
Poseidon & $2^{21}$ \\
\bottomrule
\end{tabular}
\end{center}

Tables are padded to the next power of two (with a minimum of $2^{8}$ rows). These bounds are critical for soundness: they ensure that logup multiplicities cannot overflow modulo $p$.

\subsection{Arithmetic Intermediate Representation (AIR)}\label{sec:air-eval}

If a table has $n$ columns, a transition constraint is a multivariate polynomial $C(x_1, \dots, x_n, y_1, \dots, y_n)$ in $2n$ variables, where $(x_1, \dots, x_n)$ represents the current row and $(y_1, \dots, y_n)$ represents the next row. Each table defines a set of such constraints, all of which must evaluate to zero on every pair of consecutive rows. For a table with $H$ rows (indexed $0, \dots, H-1$), the constraints are evaluated on $(H-1) + 1 = H$ pairs:
\begin{itemize}
    \item $H - 1$ consecutive pairs: $(\text{row}_i, \text{row}_{i+1})$ for $i = 0, \dots, H-2$
    \item 1 \textbf{wrapping pair}: $(\text{row}_{H-1}, \text{row}_{H-1})$ --- the last row is paired with itself
\end{itemize}

The wrapping pair means that on the last row, $\text{next}(x) = x$ for every column $x$.

\vspace{3mm}

TODO: describe how to prove AIR via sumcheck.

\subsection{Execution table}


\subsubsection{Commitment}

\fbox{At each cycle, we commit to 20 (base) field elements:}

\begin{itemize}
    \item pc (program counter)
    \item fp (frame pointer)
    % \item jump (non zero when a jump occurs)
    \item $\text{addr}_A$, $\text{addr}_B$, $\text{addr}_C$
    \item $\text{value}_A = \textbf{m}[\text{addr}_A]$, $\text{value}_B = \textbf{m}[\text{addr}_B]$, $\text{value}_C = \textbf{m}[\text{addr}_C]$
    \item 12 field elements describing the instruction being executed (see below)
\end{itemize}


\subsubsection{Instruction Encoding}

Each instruction is described by 12 field elements ($\Fp$):

\begin{itemize}
    \item 3 operands: $\text{operand}_A$, $\text{operand}_B$, $\text{operand}_C$
    \item 5 flags ($\in \{0, 1\}$): $\text{flag}_A$, $\text{flag}_B$, $\text{flag}_C$, $\text{flag}^{C}_\text{fp}$, $\text{flag}^{AB}_\text{fp}$
    \item 3 opcode flags: MUL ($\in \{0, 1\}$), JUMP ($\in \{0, 1\}$), AUX ($\in \{0, 1, 2\}$) (AUX handles both ADD and DEREF)
    \item PRECOMPILE\_DATA
\end{itemize}

$\text{flag}^{AB}_\text{fp}$ is only used by precompile instructions; for ADD, MUL, DEREF, and JUMP it is always 0.


\subsubsection{AIR transition constraints}

\fbox{We use transition constraints of degree 5.}

\vspace{5mm}

We define the following values:
\begin{itemize}
    \item $\nu_A = \text{flag}_A \cdot \text{operand}_A + (1 - \text{flag}_A - \text{flag}^{AB}_\text{fp}) \cdot \text{value}_A + \text{flag}^{AB}_\text{fp} \cdot (\text{fp} + \alpha)$ 
    \item $\nu_B = \text{flag}_B \cdot \text{operand}_B + (1 - \text{flag}_B - \text{flag}^{AB}_\text{fp}) \cdot \text{value}_B + \text{flag}^{AB}_\text{fp} \cdot (\text{fp} + \beta)$
    \item $\nu_C = \text{flag}_C \cdot \text{operand}_C + (1 - \text{flag}_C - \text{flag}_\text{fp}) \cdot \text{value}_C + \text{flag}_\text{fp} \cdot (\text{fp} + \gamma)$
\end{itemize}


With the associated constraints:
\begin{itemize}
    \item $(1 - \text{flag}_A - \text{flag}^{AB}_\text{fp}) \cdot (\text{address}_A - (\text{fp} + \text{operand}_A)) = 0$
    \item $(1 - \text{flag}_B - \text{flag}^{AB}_\text{fp}) \cdot (\text{address}_B - (\text{fp} + \text{operand}_B)) = 0$
    \item $(1 - \text{flag}_C - \text{flag}^{C}_\text{fp}) \cdot (\text{address}_C - (\text{fp} + \text{operand}_C)) = 0$
\end{itemize}

\vspace{3mm}\centerline{\rule{10cm}{0.4pt}}\vspace{5mm}

Let $P_0, P_1, P_2$ be the Lagrange basis polynomials at points $0, 1, 2$. Explicitely:

$$P_0(x) = (x-1)\cdot(x-2) / 2 \hspace{10mm} P_1(x) = x \cdot (2-x) \hspace{10mm} P_2(x) = x \cdot (x-1) / 2$$

We define the following values:

\begin{itemize}
    \item ADD = $P_1(\text{AUX})$
    \item DEREF = $P_2(\text{AUX})$
    \item IS\_PRECOMPILE = $1 - (\text{ADD} + \text{MUL} + \text{DEREF} + \text{JUMP})$
\end{itemize}

IS\_PRECOMPILE is used a "bus selector" (see \ref{buses}).

\vspace{3mm}\centerline{\rule{10cm}{0.4pt}}\vspace{5mm}

PRECOMPILE\_DATA encodes the precompile being called, and the parameters of the call:
\begin{itemize}
    \item No precompile $\rightarrow$ PRECOMPILE\_DATA $= 0$
    \item Poseidon precompile $\rightarrow$ PRECOMPILE\_DATA $= 1$
    \item Dot product precompile $\rightarrow$ PRECOMPILE\_DATA $= 2 \cdot (\texttt{is\_be} + 2\cdot \text{len})$
\end{itemize}

\vspace{3mm}\centerline{\rule{10cm}{0.4pt}}\vspace{5mm}

For addition, set AUX $= 1$.
\begin{itemize}
    \item $\text{ADD} \cdot(\nu_B - (\nu_A + \nu_C)) = 0$
\end{itemize}


\vspace{3mm}\centerline{\rule{10cm}{0.4pt}}\vspace{5mm}

For multiplication, set MUL $= 1$.
\begin{itemize}
    \item $\text{MUL} \cdot(\nu_B - \nu_A \cdot \nu_C) = 0$
\end{itemize}

\vspace{3mm}\centerline{\rule{10cm}{0.4pt}}\vspace{5mm}

For DEREF instructions, set AUX $= 2$, $\text{flag}_A = 0$, $\text{flag}_B = 1$ and $\text{flag}_C$ / $\text{flag}^{C}_\text{fp}$ according to whether the third operand is an immediate value, a memory read, or fp-relative.

The relation $\textbf{m}[\textbf{m}[\text{fp} + \alpha] + \beta] = \nu_C$ is then captured by:

\begin{itemize}
    \item $\text{DEREF} \cdot (\text{addr}_B - (\text{value}_A + \text{operand}_B)) = 0$
    \item $\text{DEREF} \cdot (\text{value}_B - \nu_C) = 0$
\end{itemize}

\vspace{3mm}\centerline{\rule{10cm}{0.4pt}}\vspace{5mm}

For (conditional) jumps, let $J = \text{JUMP} \cdot \nu_A$:
\begin{itemize}
    \item $J \cdot (1 - \nu_A) = 0$
    \item $J \cdot ( \text{next(pc)} - \nu_B) = 0$
    \item $J \cdot ( \text{next(fp)} - \nu_C) = 0$
    \item $(1 - J) \cdot ( \text{next(pc)} - (\text{pc} + 1)) = 0$
    \item $(1 - J) \cdot (\text{next(fp)} - \text{fp}) = 0$
\end{itemize}

Note: the constraint $J \cdot (1 - \nu_A) = 0$ could be removed, as long as it's correctly enforced in the bytecode.

\vspace{3mm}

TODO: Verify and (formally) prove soundness.

\subsection{Poseidon table}

TODO

\subsection{Dot product table}

See \ref{dot_product_instruction} for the instruction specification.

\subsubsection{Trace layout}

Each dot product of length $n$ occupies $n$ consecutive rows. The first row (\texttt{start} $= 1$) carries the full accumulated result; subsequent rows (\texttt{start} $= 0$) count down via \texttt{len}. Multiple dot products are stacked vertically.

\vspace{3mm}

\noindent\resizebox{\textwidth}{!}{%
\begin{tabular}{cccccccc|cccc|c}
\toprule
\multicolumn{8}{c|}{Base field columns ($\Fp$)} & \multicolumn{4}{c|}{Extension field columns ($\Fq$)} & \\
\texttt{is\_be} & \texttt{flag} & \texttt{start} & \texttt{len} & $\text{idx}_A$ & $\text{idx}_B$ & $\text{idx}_R$ & $v_{A,\Fp}$ & $v_{A,\Fq}$ & $v_B$ & \texttt{res} & \texttt{comp} & \texttt{aux} \\
\midrule
\multicolumn{13}{l}{\textit{BE dot product ($n=3$, $\alpha\!=\!90$, $\beta\!=\!200$, $\gamma\!=\!50$): \quad $\texttt{res} = \sum_{i=0}^{2} \textbf{m}[90\!+\!i] \cdot \textbf{m}[200\!+\!5i\,..\,205\!+\!5i]$}} \\[2pt]
1 & 1 & 1 & 3 & 90 & 200 & 50 & $\textbf{m}[90]$ & $\textbf{m}[90..95]$ & $\textbf{m}[200..205]$ & $\textbf{m}[50..55]$ & $c_2$ & 7 \\
1 & 0 & 0 & 2 & 91 & 205 & 50 & $\textbf{m}[91]$ & $\textbf{m}[91..96]$ & $\textbf{m}[205..210]$ & $\textbf{m}[50..55]$ & $c_1$ & 5 \\
1 & 0 & 0 & 1 & 92 & 210 & 50 & $\textbf{m}[92]$ & $\textbf{m}[92..97]$ & $\textbf{m}[210..215]$ & $\textbf{m}[50..55]$ & $c_0$ & 3 \\
\midrule
\multicolumn{13}{l}{\textit{EE dot product ($n=2$, $\alpha\!=\!300$, $\beta\!=\!400$, $\gamma\!=\!500$): \quad $\texttt{res} = \sum_{i=0}^{1} \textbf{m}[300\!+\!5i\,..\,305\!+\!5i] \cdot \textbf{m}[400\!+\!5i\,..\,405\!+\!5i]$}} \\[2pt]
0 & 1 & 1 & 2 & 300 & 400 & 500 & $\textbf{m}[300]$ & $\textbf{m}[300..305]$ & $\textbf{m}[400..405]$ & $\textbf{m}[500..505]$ & $d_1$ & 4 \\
0 & 0 & 0 & 1 & 305 & 405 & 500 & $\textbf{m}[305]$ & $\textbf{m}[305..310]$ & $\textbf{m}[405..410]$ & $\textbf{m}[500..505]$ & $d_0$ & 2 \\
\bottomrule
\end{tabular}%
}

\vspace{3mm}

\textbf{Recurrence} (over $\Fq$):
\begin{itemize}
    \item BE: $c_0 = \textbf{m}[92] \cdot \textbf{m}[210..215]$, \; $c_1 = \textbf{m}[91] \cdot \textbf{m}[205..210] + c_0$, \; $c_2 = \textbf{m}[90] \cdot \textbf{m}[200..205] + c_1 = \texttt{res}$
    \item EE: $d_0 = \textbf{m}[305..310] \cdot \textbf{m}[405..410]$, \; $d_1 = \textbf{m}[300..305] \cdot \textbf{m}[400..405] + d_0 = \texttt{res}$
\end{itemize}

\vspace{2mm}

Notes: In BE mode, $\text{idx}_A$ increments by 1 (base field elements); in EE mode, by 5 (extension field elements). $\text{idx}_B$ always increments by 5. $\texttt{aux} = \texttt{is\_be} + 2 \cdot \texttt{len}$ is a non-committed column (used only for bus fingerprinting). Both $v_{A,\Fp}$ and $v_{A,\Fq}$ are read from memory on every row, but only the relevant one (depending on \texttt{is\_be}) is used in the computation.

\subsubsection{Columns}

\fbox{8 base field columns + 4 extension field columns = 28 $\Fp$-columns.}

\vspace{3mm}

\textbf{Base field columns ($\Fp$):}
\begin{itemize}
    \item \texttt{is\_be} $\in \{0,1\}$: mode flag (1 = base$\times$extension, 0 = extension$\times$extension)
    \item \texttt{flag} $\in \{0,1\}$: bus selector (1 only on the first row of a real (non-padding) dot product)
    \item \texttt{start} $\in \{0,1\}$: 1 on the first row of each group (and on padding rows)
    \item \texttt{len}: countdown from $n$ to $1$
    \item $\text{idx}_A$, $\text{idx}_B$, $\text{idx}_R$: memory addresses for $A$, $B$, and the result
    \item $v_{A,\Fp}$: base field value $\textbf{m}[\text{idx}_A]$ (used in BE mode)
\end{itemize}

\textbf{Extension field columns ($\Fq$):}
\begin{itemize}
    \item $v_{A,\Fq}$: extension field value $\textbf{m}[\text{idx}_A .. \text{idx}_A + 5]$
    \item $v_B$: extension field value $\textbf{m}[\text{idx}_B .. \text{idx}_B + 5]$
    \item \texttt{res}: result value $\textbf{m}[\text{idx}_R .. \text{idx}_R + 5]$
    \item \texttt{comp}: running computation (accumulated dot product)
\end{itemize}

\textbf{Non-committed column} (used for bus fingerprinting):
\begin{itemize}
    \item \texttt{aux} $= 2 \cdot (\texttt{is\_be} + 2 \cdot \texttt{len})$
\end{itemize}

\subsubsection{Memory lookups}
Every row performs:
\begin{itemize}
    \item 1 base field lookup: $v_{A,\Fp} = \textbf{m}[\text{idx}_A]$
    \item 3 extension field lookups: $v_{A,\Fq} = \textbf{m}[\text{idx}_A..+5]$, $\; v_B = \textbf{m}[\text{idx}_B..+5]$, $\; \texttt{res} = \textbf{m}[\text{idx}_R..+5]$
\end{itemize}

\subsubsection{Bus interaction}
On rows where $\texttt{flag} = 1$, the table \textsc{Pull}s $(\text{idx}_A, \text{idx}_B, \text{idx}_R, \texttt{aux})$ from the corresponding bus. The execution table \textsc{Push}es a matching tuple for each dot product instruction.

The \texttt{aux} encoding ensures both the mode and the length are bound to the bus data. Since \texttt{is\_be} is constrained to be boolean (constraint~\ref{dot:bool-isbe}), if an adversary flips \texttt{is\_be} while keeping \texttt{aux} constant, the adversary would need a length $\texttt{len}'$ such that $\texttt{aux} = (1 - \texttt{is\_be}) + 2 \cdot \texttt{len}'$, i.e.\ $2\cdot\texttt{len}' = 2\cdot\texttt{len} \pm 1$ over $\Fp$. By Lemma~\ref{lem:len-bound}, both $\texttt{len}$ and $\texttt{len}'$ are $\leq 2^{21} < p/2$, so the equation cannot overflow modulo $p$ and must hold over $\mathbb{Z}$. Over $\mathbb{Z}$, this is impossible by parity.

Finally, $\texttt{len}$ should always be $> 0$ (it's part of the bytecode, and thus cannot be tampered with by the adversary), which ensures that \texttt{aux} is always $\geq 2$ (using lemma \ref{lem:len-bound} again, preventing overflow modulo $p$), and thus different from the poseidon precompile encoding (1).

\subsubsection{AIR constraints}

We write $\text{next}(x)$ for the value of column $x$ on the \textbf{next row} (down).

\vspace{3mm}

\textbf{Value selection:} Define
$$v_A = \texttt{is\_be} \cdot v_{A,\Fp} + (1 - \texttt{is\_be}) \cdot v_{A,\Fq} \;\in \Fq$$

\textbf{Constraints:}
\begin{enumerate}
    \item\label{dot:bool-start} $\texttt{start} \cdot (1 - \texttt{start}) = 0$ \hfill (\texttt{start} is boolean)
    \item\label{dot:bool-flag} $\texttt{flag} \cdot (1 - \texttt{flag}) = 0$ \hfill (\texttt{flag} is boolean)
    \item\label{dot:bool-isbe} $\texttt{is\_be} \cdot (1 - \texttt{is\_be}) = 0$ \hfill (\texttt{is\_be} is boolean)
    \item\label{dot:flag-start} $\texttt{flag} \cdot (1 - \texttt{start}) = 0$ \hfill (\texttt{flag} $\Rightarrow$ \texttt{start})
    \item\label{dot:mode-consistent} $(\text{next}(\texttt{is\_be}) - \texttt{is\_be})^2 \cdot (1 - \text{next}(\texttt{start})) = 0$ \hfill (mode consistent within group)
    \item\label{dot:recurrence} $\texttt{comp} - v_A \cdot v_B - \text{next}(\texttt{comp}) \cdot (1 - \text{next}(\texttt{start})) = 0$ \hfill (recurrence, over $\Fq$)
    \item\label{dot:len-decrement} $(1 - \text{next}(\texttt{start})) \cdot (\texttt{len} - \text{next}(\texttt{len}) - 1) = 0$ \hfill (length countdown)
    \item\label{dot:len-terminate} $\text{next}(\texttt{start}) \cdot (\texttt{len} - 1) = 0$ \hfill (must reach 1 before new group)
    \item\label{dot:idx-a} $(1 - \text{next}(\texttt{start})) \cdot (\text{idx}_A - \text{next}(\text{idx}_A) + \delta_A) = 0$ \hfill (with $\delta_A = 5(1 - \texttt{is\_be}) + \texttt{is\_be}$)
    \item\label{dot:idx-b} $(1 - \text{next}(\texttt{start})) \cdot (\text{idx}_B - \text{next}(\text{idx}_B) + 5) = 0$
    \item\label{dot:result} $(\texttt{comp} - \texttt{res}) \cdot \texttt{start} = 0$ \hfill (result check, over $\Fq$)
\end{enumerate}

Constraint~\ref{dot:recurrence}: when $\text{next}(\texttt{start}) = 1$ (next row starts a new group), the tail term vanishes: $\texttt{comp} = v_A \cdot v_B$. Otherwise the partial sum is accumulated. Constraint~\ref{dot:result}: on the first row of each group, the accumulated computation must equal the result read from memory.


TODO: Verify and (formally) prove soundness.

\begin{lemma}\label{lem:len-bound}
On every row $r$ of the dot product table, $\texttt{len}_r \leq H - r$ (as an integer in $\{0, \dots, p-1\}$), where $H \leq 2^{21}$ is the table height. In particular, $\texttt{len}_r \leq H$.
\end{lemma}

\begin{proof}
By backward induction on $r$, from $r = H - 1$ down to $r = 0$.

\vspace{2mm}

\textbf{Base case ($r = H - 1$):} On the wrapping pair (row $H\!-\!1$ paired with itself, see Section~\ref{sec:air-eval}), $\text{next}(x) = x$ for every column $x$. Constraint~\ref{dot:len-decrement} becomes $(1 - \texttt{start}) \cdot (\texttt{len} - \texttt{len} - 1) = -(1 - \texttt{start}) = 0$, forcing $\texttt{start}_{H-1} = 1$. Then constraint~\ref{dot:len-terminate} becomes $1 \cdot (\texttt{len} - 1) = 0$, giving $\texttt{len}_{H-1} = 1 = H - (H-1)$. 

\vspace{2mm}

\textbf{Inductive step ($r < H - 1$):} Assume $\texttt{len}_s \leq H - s$ for all $s > r$. The pair (row $r$, row $r\!+\!1$) gives two cases depending on $\texttt{start}_{r+1} \in \{0,1\}$ (constraint~\ref{dot:bool-start}):

\begin{itemize}
    \item If $\texttt{start}_{r+1} = 1$: constraint~\ref{dot:len-terminate} gives $1 \cdot (\texttt{len}_r - 1) = 0$, so $\texttt{len}_r = 1 \leq H - r$.
    \item If $\texttt{start}_{r+1} = 0$: constraint~\ref{dot:len-decrement} gives $(1 - 0) \cdot (\texttt{len}_r - \texttt{len}_{r+1} - 1) = 0$, so $\texttt{len}_r = \texttt{len}_{r+1} + 1$ in $\Fp$. By induction, $\texttt{len}_{r+1} \leq H - (r+1)$, so $\texttt{len}_{r+1} + 1 \leq H - r$. Since $H - r \leq H \leq 2^{21} < p$, the addition does not overflow modulo $p$, so $\texttt{len}_r = \texttt{len}_{r+1} + 1 \leq H - r$ as integers. 
\end{itemize}
\end{proof}

\subsection{Data flow between tables / memory}


\begin{lemma}
    Let $a_0, a_1, \ldots, a_{n-1}$ be pairwise distinct poles in $\Fq$, and let $m_0, m_1, \ldots, m_{n-1}$ be an associated list of multiplicities in $\{0, 1, \dots, p - 1\}$. Consider the rational function:
$$P(X) = \sum_{i=0}^{n-1} \frac{m_i}{X - a_i}$$

Except with probability $n/q$, if $P(\alpha) = 0$ for a random $\alpha \in \Fq$, then all multiplicities $m_i = 0$.

\end{lemma}

\subsubsection{Indexed Lookup into Memory}

We use logup \cite{logup}, in its indexed form, to allow tables to perform lookups into the read-only memory.


\vspace{3mm}

Let $\mathcal{T}$ denote the set of all tables in the system. For each table $T \in \mathcal{T}$ with $H_T$ rows, let $n_T$ denote the number of memory lookups. Each lookup $i < n_T$ consists of an \textbf{index column} $\text{col}_{\text{index},T,i}$ and a \textbf{value column} $\text{col}_{\text{val},T,i}$.

\vspace{3mm}

The rule to enforce is the following:
$$\forall T \in \mathcal{T}, \forall i < n_T, \forall j < H_T: \quad \text{col}_{\text{val},T,i}(j) = \textbf{m}[\text{col}_{\text{index},T,i}(j)]$$

Implicitly, we must also have $\text{col}_{\text{index},T,i}(j) < M$ (the memory size).

\vspace{3mm}

The prover initially commits to a multilinear polynomial $\textit{acc}$, having the same size as the memory, such that (in the honest case) for every $k < M$:
$$\textit{acc}[k] = \sum_{T \in \mathcal{T}} \sum_{i < n_T} \left| \{ j < H_T : \text{col}_{\text{index},T,i}(j) = k \} \right|$$
i.e., $\textit{acc}[k]$ represents the total number of times address $k$ is accessed by the lookups across all tables.

\vspace{3mm}

The verifier sends a random challenge $\alpha \in \Fq$ (TODO quantify soundness error). Let $N = \sum_{T \in \mathcal{T}} n_T \cdot H_T$ be the total number of memory lookups. Assuming $N < p$ (to avoid overflow), the indexed lookup into memory is valid, except with probability $(N + M)/q$, if for a randomly sampled $X \in \Fq$:

$$\sum_{T \in \mathcal{T}} \sum_{i<n_T} \sum_{j<H_T} \frac{1}{X - (\text{col}_{\text{index},T,i}(j) + \alpha \cdot \text{col}_{\text{val},T,i}(j))} = \sum_{k<M} \frac{\textit{acc}(k)}{X - (k + \alpha \cdot \textbf{m}[k])}$$

This can be computed via GKR, as introduced in \cite{logup_gkr}.

\subsubsection{Precompile bus: Data flow between tables}\label{buses}

See OpenVM \cite{openvm}, definition 2.2.2, for more details.

At each cycle when IS\_PRECOMPILE = 1, the execution table \textsc{Push}es $$\sigma = (\text{PRECOMPILE\_DATA}, \nu_A, \nu_B, \nu_C)$$ to the "precompile bus".

In case of Poseidon call, PRECOMPILE\_DATA = 1 and $\nu_A$, $\nu_B$, $\nu_C$ represent the left input address, the right input address, and the output address (3 pointers to a chunk of 8 field elements in memory).

In case of dot product call, PRECOMPILE\_DATA $= 2 \cdot (\texttt{is\_be} + 2 \cdot \texttt{len})$ encodes both the mode and the length, and $\nu_A$, $\nu_B$, $\nu_C$ represent the address of the left slice, the address of the right slice, and the address of the result.

Each such tuple $\sigma$ (counting multiplicity) must be \textsc{Pulled} by one of the precompile tables. Given that the Poseidon table only pulls tuples with PRECOMPILE\_DATA $= 1$, and the dot product table only pulls tuples with PRECOMPILE\_DATA $\geq 4$ (since $\texttt{len} \geq 1$), the bus is effectively partitioned into two disjoint sub-buses, one for each precompile.

Similarly to the IS\_PRECOMPILE (virtual) column for the execution table, each one of the two precompile tables has a boolean (virtual) column acting as a bus selector, indicating at which rows the table is pulling from the bus (1) or not (0).

\vspace{3mm}

\textbf{Balance rule:} At the end of execution, for each tuple $\sigma$, the number of pushes must equal the number of pulls accross the 3 tables: execution, poseidon, and dot product.

\vspace{5mm}

\textbf{Proving system (logup):}

Let $\mathcal{T}$ denote the set of all tables in the system. Each table $T \in \mathcal{T}$ has $H_T$ rows. The bus interaction of the table $T$ is defined by:
\begin{itemize}
    \item $\text{dir}_{T} \in \{+1, -1\}$: the direction ($+1$ for \textsc{Push}, $-1$ for \textsc{Pull})
    \item $\text{sel}_{T}: [0, H_T) \to \{0, 1\}$: the selector (virtual) column
    \item $\sigma_{T} = (\sigma_0, \ldots, \sigma_{k-1})$: the $k$ data columns
\end{itemize}

\vspace{3mm}

The verifier sends a random challenge $\alpha \in \Fq$. Define the encoding of a tuple $\sigma = (\sigma_0, \ldots, \sigma_{k-1})$ by:
$$\text{encode}(\sigma_0, \ldots, \sigma_{k-1}) = \sum_{i=0}^{k-1} \alpha^{i} \cdot \sigma_i$$

\vspace{3mm}

Except with negligible probability probability (TODO quantify precisely), the bus is balanced if for a randomly sampled $X \in \Fq$:

$$\sum_{T \in \mathcal{T}} \sum_{j=0}^{H_T - 1} \frac{\text{dir}_{T} \cdot \text{sel}_{T}(j)}{X - \text{encode}(\sigma_{T}(j))} = 0$$


\vspace{3mm}

\textit{Overflow constraint:} We must ensure that multiplicities do not overflow modulo $p$. This is enforced by limitting the maximum height of each table.

\vspace{3mm}

As with the indexed lookup into memory, this sum can be computed efficiently via GKR \cite{logup_gkr}. In practice, all logup instances (bus balance and memory lookups) are batched into a single GKR instance, using an addition field element passed to the encoding tuple for domain separation: LOGUP\_MEMORY = 0 for the memory interraction, and LOGUP\_PRECOMPILE = 1.

\vspace{3mm} TODO: Unified vision in which memory is just another table, and memory accesses are just bus interactions?

A detailled soundness analysis can be found in \href{https://github.com/openvm-org/stark-backend/blob/main/docs/Soundness_of_Interactions_via_LogUp.pdf}{Soundness of Interactions via LogUp}.

\subsection{Simple stacking of multilinear polynomials}

\textit{Note 1}: It's always possible to reduce $n$ claims about a multilinear polynomial to a single one, using sumcheck. But this trick is not necessary with WHIR, which natively supports an arbitrary number of claims about the committed polynomial.
\vspace{3mm}

\textit{Note 2:} Crucially, the proving cost to add an equality constraint of the form $P((x_1, \dots, x_n)) = y$ to a committed polynomial $P$ via WHIR is $O(2^k)$ where $k = {|\{i, x_i \notin \{0, 1\} \}|}$ is the number of "non-boolean variables". As a result, adding "sparse" ($(x_i)$ containing boolean values) equality constraints is essentially optimal.

\vspace{3mm}

% One of the advantage of multilinear polynomials versus univariate polynomials is the ability to efficienty commit to multiple polynomials at once.
In order to commit to multiple univariate polynomials with FRI, each polynomial must be FFT-ed + Merkle-committed.
Even if it's possible to have some batching at the Merkle tree level (see 'MMCS' in \href{https://github.com/Plonky3/Plonky3}{Plonky3}), the proof size for multiple, complex AIR tables quickly reach the megabyte scale.

With a multilinear PCS (such as WHIR), we can "concatenate" multiple multilinear polynomials into a single one, and commit to it once (offering significant proof size savings).

\vspace{5mm}

More details: Given $n$ multilinear polynomials $P_1, \dots, P_n$ with $\nu_1, \dots, \nu_n$ variables respectively, we order them from the \textbf{largest to the smallest} and concatenate their respective evaluation (on the boolean hypercube):

$$P = [P_1(\{0,1\}^{\nu_1}) \| P_2(\{0,1\}^{\nu_2}) \| \dots \| P_n(\{0,1\}^{\nu_n})]$$

After padding with zeros to the next power of two, we can interpret the result as the evaluations (on the boolean hypercube) of a multilinear polynomial, with $\nu = \lceil \log_2(\sum_i 2^{\nu_i}) \rceil$ variables, and commit to it.

To reduce an evaluation claim on an "inner" (smaller) polynomial $P_i$ to a claim on the "outer" (larger) polynomial $P$, we use \textbf{boolean selectors}.

\vspace{5mm}

Example: Consider 3 multilinear polynomials $P_1, P_2, P_3$ with 4, 3, and 2 variables respectively.
The concatenated polynomial $P$, that we commit, has $5 = \lceil \log_2(2^4 + 2^3 + 2^2) \rceil$ variables.

\begin{itemize}
    \item $P_1(x_1, x_2, x_3, x_4) = P(0, x_1, x_2, x_3, x_4)$
    \item $P_2(x_1, x_2, x_3) = P(1, 0, x_1, x_2, x_3)$
    \item $P_3(x_1, x_2) = P(1, 1, 0, x_1, x_2)$
\end{itemize}

\begin{figure}[h]
\centering
\begin{tikzpicture}[scale=0.45, every node/.style={font=\small}]
    \fill[gray!10] (0,0) rectangle (16,1.5);
    \fill[gray!20] (16,0) rectangle (24,1.5);
    \fill[gray!10] (24,0) rectangle (28,1.5);
    \fill[gray!20] (28,0) rectangle (32,1.5);

    \draw[black] (0,0) rectangle (32,1.5);
    \draw[black] (16,0) -- (16,1.5);
    \draw[black] (24,0) -- (24,1.5);
    \draw[black] (28,0) -- (28,1.5);

    \node at (8,0.75) {$P_1$};
    \node at (20,0.75) {$P_2$};
    \node at (26,0.75) {$P_3$};
    \node at (30,0.75) {padding};

    \node[below] at (0,-0.1) {\footnotesize 0};
    \node[below] at (16,-0.1) {\footnotesize 16};
    \node[below] at (24,-0.1) {\footnotesize 24};
    \node[below] at (28,-0.1) {\footnotesize 28};
    \node[below] at (32,-0.1) {\footnotesize 32};

    % Selector annotations above each section
    \node[above] at (8,1.6) {$P({\mathbf{0}}, x_1, x_2, x_3, x_4)$};
    \node[above] at (20,1.6) {$P({\mathbf{1}}, {\mathbf{0}}, x_1, x_2, x_3)$};
    \node[above] at (26,1.6) {$P({\mathbf{1}}, {\mathbf{1}}, {\mathbf{0}}, x_1, x_2)$};
\end{tikzpicture}
\caption{Simple stacking of $P_1, P_2, P_3$ into a single polynomial $P$}
\label{fig:stacking}
\end{figure}

Advantage of this approach: simplicity.

Drawback: padding overhead, i.e. it does not take advantage of the potential repetions at the end of each inner polynomial's evaluations.

\vspace{5mm}

There are alterntive ways to handle the stacking of multiple multilinear polynomials:

\begin{itemize}
    \item \textbf{Jagged PCS} \cite{jagged_pcs}: No padding overhead, at the cost of an additional sumcheck.
    \item  \textbf{Per-polynomial chunking}: decompose the non-repeated par of each inner polynomial into a small (think 3 or 4) number of power-of-two sized chunks, and concatenate all these chunks into a single large polynomial.
\end{itemize}

\textit{Note 3:} A meticulous implementation of WHIR could also take advantage of any potential repetitions in the committed polynomial, both at the FFT and the sumcheck level, leaving the Merklelisation as the main overhead.

\section{Recursive Aggregation}\label{sec:recursive-aggregation}

The recursive aggregation program (see Figure~\ref{fig:recursive-aggregation}) attests that a set of public keys have valid signatures for a given message. It partitions the signers into $n_{\text{rec}} + 1$ sources: one \textbf{direct source} whose XMSS signatures are verified explicitly, and $n_{\text{rec}} \geq 0$ \textbf{recursive sources}, each accompanied by a sub-proof that is recursively verified.

For each recursive source, the program runs the leanVM verifier on the provided sub-proof, confirming that the sub-proof itself is a valid recursive aggregation proof covering the source's signers. When $n_{\text{rec}} = 0$, the program simply verifies all signatures directly.

\subsection{Bytecode evaluation claims}\label{sec:bytecode-reduction}

A key subtlety arises from recursion. Every leanVM proof is tied to a specific \emph{bytecode} --- the program that was executed, represented as a multilinear polynomial. In our case, there is a single program (that both contain signature verification and recursion algorithms). The leanVM verification algorithm requires evaluating the bytecode polynomial at a random point.

When the recursive aggregation program verifies a sub-proof, it runs the leanVM verifier \emph{inside} the program. This verification produces a bytecode evaluation claim. For efficiency, rather than checking it inside the program (with a PCS), the claim is forwarded to the public input, to be checked externally.

However, each sub-proof is potentially itself a recursive aggregation, and may have already forwarded its own bytecode claim in the same way. So for each of the $n_{\text{rec}}$ sub-proofs, \textbf{two} bytecode claims arise:

\begin{enumerate}
    \item \textbf{Inner-public-memory claim}: The bytecode claim that the sub-proof forwarded from its own recursive verifications (read from the sub-proof's public input).

    \item \textbf{Inner-proof claim}: The new bytecode claim produced by verifying the sub-proof itself.
\end{enumerate}

After verifying all $n_{\text{rec}}$ sub-proofs, a fresh Fiat--Shamir transcript is initialized and fed with all $2 n_{\text{rec}}$ evaluation points and claimed values. This transcript produces a random linear combination challenge, and the $2 n_{\text{rec}}$ claims are then batched into a single one via sumcheck, yielding a reduced claim. This reduced claim is written to the public input for the next level of recursion.

When $n_{\text{rec}} = 0$ (no recursion), the bytecode claim in the public input is set to zero.


\subsection{Signer partitioning}\label{sec:signer-partitioning}

\emph{
In the following, we assume  the message being signed is common to all signers (typically the case at Ethereum's consensus layer), but the scheme can be naturally adapted to distinct messages.}

\vspace{3mm}

Consider an aggregation of $n_{\text{sigs}}$ (distinct) signatures. The $n_{\text{sigs}}$ (distinct) public keys are part of the "public input" in memory. The aggregation program must ensure that each public key is verified by at least one of the $1 + n_{\text{rec}}$ sources (duplications allowed: some public keys may be verified by multiple sources).

Let $n_{\text{dup}}$ be the total number of duplicated public keys across sources, counted with multiplicity. To ensure ensure valid partionning, we use the following algorithm:

\begin{itemize}
    \item Initialize a counter $c \gets 0$.
    \item Initialize a (write-once) array $B$ of size $n_{\text{total}} = n_{\text{sigs}} + n_{\text{dup}}$.
    \item For each source $s$, for each signature index $i \in [0, n_{\text{total}})$ verified by $s$, write $B[i] \gets c$ and increment $c$.
    \item At the end, assert $c = n_{\text{total}}$.
\end{itemize}

\clearpage
\bibliographystyle{IEEEtran}
\bibliography{bibliography}

\end{document}